{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Python 資料分析\n",
    "\n",
    "> 以 Python 擷取網路資料\n",
    "\n",
    "[數據交點](https://www.datainpoint.com/) | 郭耀仁 <yaojenkuo@datainpoint.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 練習題指引\n",
    "\n",
    "- 第一個程式碼儲存格會將可能用得到的模組（套件）以及單元測試 `unittest` 載入。\n",
    "- 如果練習題需要載入檔案，檔案與練習題存放在同個資料夾中，意即我們可以指定工作目錄來載入。\n",
    "- 練習題已經定義好函數或者類別的名稱以及參數名稱，我們只需要寫作主體。\n",
    "- 函數或者類別的 `\"\"\"docstring\"\"\"` 部分會描述測試如何進行。\n",
    "- 觀察 `\"\"\"docstring\"\"\"` 的部分能夠暸解輸入以及預期輸出之間的關係，能幫助我們更暸解題目。\n",
    "- 請在 `### BEGIN SOLUTION` 與 `### END SOLUTION` 這兩個單行註解之間寫作函數或者類別的主體。\n",
    "- 執行測試的方式為點選上方選單的 Kernel -> Restart Kernel And Run All Cells -> Restart。\n",
    "- 可以每寫一題就執行測試，也可以全部寫完再執行測試。\n",
    "- 練習題閒置超過 10 分鐘會自動斷線，這時只要重新點選練習題連結即可重新啟動。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Define a function named `extract_team_names` that is able to extract the team names of NBA given a JSON file.\n",
    "\n",
    "- Expected inputs: a JSON file.\n",
    "- Expected outputs: a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_team_names(json_file):\n",
    "    \"\"\"\n",
    "    >>> team_names = extract_team_names('teams.json')\n",
    "    >>> len(team_names)\n",
    "    30\n",
    "    >>> \"Boston Celtics\" in team_names\n",
    "    True\n",
    "    >>> \"Brooklyn Nets\" in team_names\n",
    "    True\n",
    "    >>> \"Los Angeles Lakers\" in team_names\n",
    "    True\n",
    "    >>> \"Phoenix Suns\" in team_names\n",
    "    True\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    with open(json_file) as jf:\n",
    "        teams_dict = json.load(jf)\n",
    "    nba_teams = teams_dict['league']['standard']\n",
    "    team_names = [e['fullName'] for e in nba_teams if e['isNBAFranchise']]\n",
    "    return team_names\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Define a function named `extract_store_addresses` that is able to extract the store addresses of 7-11 conveniece stores in Xinyi District, Taipei given a XML file.\n",
    "\n",
    "- Expected inputs: a XML file.\n",
    "- Expected outputs: a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_store_addresses(xml_file):\n",
    "    \"\"\"\n",
    "    >>> store_addresses = extract_store_addresses('stores.xml')\n",
    "    >>> len(store_addresses)\n",
    "    74\n",
    "    >>> '台北市信義區信義路五段7號35樓' in store_addresses\n",
    "    True\n",
    "    >>> '台北市信義區吳興街156巷2弄2號4號1樓' in store_addresses\n",
    "    True\n",
    "    >>> '台北市信義區忠孝東路五段68號24樓' in store_addresses\n",
    "    True\n",
    "    >>> '台北市信義區虎林街85號' in store_addresses\n",
    "    True\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    root = ET.parse(xml_file)\n",
    "    address_xpath = './/Address'\n",
    "    store_addresses = [e.text for e in root.findall(address_xpath)]\n",
    "    return store_addresses\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Define a function named `extract_movie_titles` that is able to extract the titles of top rated movies from IMDb.com given a HTML file.\n",
    "\n",
    "- Expected inputs: a HTML file.\n",
    "- Expected outputs: a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_movie_titles(html_file):\n",
    "    \"\"\"\n",
    "    >>> movie_titles = extract_movie_titles('movies.html')\n",
    "    >>> len(movie_titles)\n",
    "    250\n",
    "    >>> 'The Shawshank Redemption' in movie_titles\n",
    "    True\n",
    "    >>> 'The Godfather' in movie_titles\n",
    "    True\n",
    "    >>> 'The Dark Knight' in movie_titles\n",
    "    True\n",
    "    >>> 'Forrest Gump' in movie_titles\n",
    "    True\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    with open(html_file) as hf:\n",
    "        soup = BeautifulSoup(hf)\n",
    "    movie_titles = [e.text for e in soup.select('.titleColumn a')]\n",
    "    return movie_titles\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Define a function named `extract_movie_ratings` that is able to extract the ratings of top rated movies from IMDb.com given a HTML file.\n",
    "\n",
    "- Expected inputs: a HTML file.\n",
    "- Expected outputs: a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_movie_ratings(html_file):\n",
    "    \"\"\"\n",
    "    >>> movie_ratings = extract_movie_ratings('movies.html')\n",
    "    >>> len(movie_ratings)\n",
    "    250\n",
    "    >>> max(movie_ratings)\n",
    "    9.2\n",
    "    >>> min(movie_ratings)\n",
    "    8.0\n",
    "    >>> sum(movie_ratings) / len(movie_ratings)\n",
    "    8.253999999999975\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    with open(html_file) as hf:\n",
    "        soup = BeautifulSoup(hf)\n",
    "    movie_ratings = [float(e.text) for e in soup.select('strong')]\n",
    "    return movie_ratings\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Define a function named `extract_movie_table` that is able to extract the ranking, titles, release_years, and ratings of top rated movies from IMDb.com given a HTML file.\n",
    "\n",
    "- Expected inputs: a HTML file.\n",
    "- Expected outputs: a (250, 4) DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_movie_table(html_file):\n",
    "    \"\"\"\n",
    "    >>> movie_table = extract_movie_table('movies.html')\n",
    "    >>> print(movie_table)\n",
    "         ranking                     title  release_year  rating\n",
    "    0          1  The Shawshank Redemption          1994     9.2\n",
    "    1          2             The Godfather          1972     9.1\n",
    "    2          3    The Godfather: Part II          1974     9.0\n",
    "    3          4           The Dark Knight          2008     9.0\n",
    "    4          5              12 Angry Men          1957     8.9\n",
    "    ..       ...                       ...           ...     ...\n",
    "    245      246        The Princess Bride          1987     8.0\n",
    "    246      247     The Battle of Algiers          1966     8.0\n",
    "    247      248              Winter Sleep          2014     8.0\n",
    "    248      249                Tangerines          2013     8.0\n",
    "    249      250            The Terminator          1984     8.0\n",
    "\n",
    "    [250 rows x 4 columns]\n",
    "    >>> print(type(movie_table))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    >>> print(movie_table.shape)\n",
    "    (250, 4)\n",
    "    >>> print(movie_table[\"release_year\"].min())\n",
    "    1921\n",
    "    >>> print(movie_table[\"release_year\"].max())\n",
    "    2020\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    with open(html_file) as hf:\n",
    "        soup = BeautifulSoup(hf)\n",
    "    movie_titles = [e.text for e in soup.select('.titleColumn a')]\n",
    "    release_years = [int(e.text.replace(\"(\", \"\").replace(\")\", \"\")) for e in soup.select('.secondaryInfo')]\n",
    "    movie_ratings = [float(e.text) for e in soup.select('strong')]\n",
    "    movie_df = pd.DataFrame()\n",
    "    movie_df[\"ranking\"] = list(range(1, len(movie_titles)+1))\n",
    "    movie_df[\"title\"] = movie_titles\n",
    "    movie_df[\"release_year\"] = release_years\n",
    "    movie_df[\"rating\"] = movie_ratings\n",
    "    return movie_df\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. Define a function named `extract_dark_knight_release_dates` that is able to extract the titles and release dates from <https://simple.wikipedia.org/wiki/The_Dark_Knight_Trilogy>.\n",
    "\n",
    "- Expected inputs: a URL.\n",
    "- Expected outputs: 2 lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dark_knight_release_dates(request_url):\n",
    "    \"\"\"\n",
    "    >>> titles, release_dates = extract_dark_knight_release_dates(\"https://simple.wikipedia.org/wiki/The_Dark_Knight_Trilogy\")\n",
    "    >>> print(titles)\n",
    "    ['Batman Begins', 'The Dark Knight', 'The Dark Knight Rises']\n",
    "    >>> print(release_dates)\n",
    "    ['June 15, 2005', 'July 18, 2008', 'July 20, 2012']\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    response = requests.get(request_url)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    titles = [e.text for e in soup.select(\"tbody tr td i\")][:3]\n",
    "    release_dates = [e.text.strip() for e in soup.select(\"td:nth-child(2)\")][:3]\n",
    "    return titles, release_dates\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. Define a function named `extract_dark_knight_box_offices` that is able to extract the titles and worldwide box offices from <https://simple.wikipedia.org/wiki/The_Dark_Knight_Trilogy>.\n",
    "\n",
    "- Expected inputs: a URL.\n",
    "- Expected outputs: 2 lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dark_knight_box_offices(request_url):\n",
    "    \"\"\"\n",
    "    >>> titles, box_offices = extract_dark_knight_box_offices(\"https://simple.wikipedia.org/wiki/The_Dark_Knight_Trilogy\")\n",
    "    >>> print(titles)\n",
    "    ['Batman Begins', 'The Dark Knight', 'The Dark Knight Rises']\n",
    "    >>> print(box_offices)\n",
    "    ['$374,218,673', '$1,004,934,033', '$1,084,939,099']\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    response = requests.get(request_url)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    titles = [e.text for e in soup.select(\"tbody tr td i\")][:3]\n",
    "    box_offices = [e.text.strip() for e in soup.select(\"td:nth-child(6)\")]\n",
    "    return titles, box_offices\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. Define a function named `extract_dark_knight_trilogy` that is able to extract the specified information from <https://simple.wikipedia.org/wiki/The_Dark_Knight_Trilogy> as a DataFrame.\n",
    "\n",
    "- Expected inputs: a URL.\n",
    "- Expected outputs: a (3, 3) DataFrame.\n",
    "\n",
    "```\n",
    "                   title release_date  box_office\n",
    "0          Batman Begins   2005-06-15   374218673\n",
    "1        The Dark Knight   2008-07-18  1004934033\n",
    "2  The Dark Knight Rises   2012-07-20  1084939099\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dark_knight_trilogy(request_url):\n",
    "    \"\"\"\n",
    "    >>> dark_knight_trilogy = extract_dark_knight_trilogy(\"https://simple.wikipedia.org/wiki/The_Dark_Knight_Trilogy\")\n",
    "    >>> print(type(dark_knight_trilogy))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    >>> print(dark_knight_trilogy.shape)\n",
    "    (3, 3)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    response = requests.get(request_url)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    titles = [e.text for e in soup.select(\"tbody tr td i\")][:3]\n",
    "    box_offices = [e.text.strip() for e in soup.select(\"td:nth-child(6)\")]\n",
    "    box_offices = [int(i.replace(\"$\", \"\").replace(\",\", \"\")) for i in box_offices]\n",
    "    release_dates = [e.text.strip() for e in soup.select(\"td:nth-child(2)\")][:3]\n",
    "    split_release_dates = [i.split() for i in release_dates]\n",
    "    month_dict = {\n",
    "        \"June\": \"06\",\n",
    "        \"July\": \"07\"\n",
    "    }\n",
    "    release_dates_to_df = []\n",
    "    for lst in split_release_dates:\n",
    "        month_part = month_dict[lst[0]]\n",
    "        day_part = lst[1].replace(\",\", \"\")\n",
    "        year_part = lst[2]\n",
    "        release_date = \"{}-{}-{}\".format(year_part, month_part, day_part)\n",
    "        release_dates_to_df.append(release_date)\n",
    "    out_df = pd.DataFrame()\n",
    "    out_df[\"title\"] = titles\n",
    "    out_df[\"release_date\"] = release_dates_to_df\n",
    "    out_df[\"box_office\"] = box_offices\n",
    "    return out_df\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Define a function named `extract_lord_of_the_rings_trilogy` that is able to extract the specified information from <https://en.wikipedia.org/wiki/The_Lord_of_the_Rings_(film_series)> as a DataFrame.\n",
    "\n",
    "- Expected inputs: a URL.\n",
    "- Expected outputs: a (3, 3) DataFrame.\n",
    "\n",
    "```\n",
    "                        title release_date  box_office\n",
    "0  The Fellowship of the Ring   2001-12-19   897690072\n",
    "1              The Two Towers   2002-12-18   947495095\n",
    "2      The Return of the King   2003-12-17  1146030912\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lord_of_the_rings_trilogy(request_url):\n",
    "    \"\"\"\n",
    "    >>> lord_of_the_rings_trilogy = extract_lord_of_the_rings_trilogy(\"https://en.wikipedia.org/wiki/The_Lord_of_the_Rings_(film_series)\")\n",
    "    >>> print(type(lord_of_the_rings_trilogy))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    >>> print(lord_of_the_rings_trilogy.shape)\n",
    "    (3, 3)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    response = requests.get(request_url)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    titles = [e.text for e in soup.select(\"i a\")][1:4]\n",
    "    box_offices = [e.text.strip() for e in soup.select(\"tr~ tr+ tr td:nth-child(5)\")]\n",
    "    box_offices = [int(i.replace(\"$\", \"\").replace(\",\", \"\")) for i in box_offices]\n",
    "    release_dates = [e.text.strip().replace(\"\\xa0\", \" \") for e in soup.select(\"td+ td:nth-child(2)\")][3:6]\n",
    "    split_release_dates = [i.split() for i in release_dates]\n",
    "    release_dates_to_df = [lst[3].replace(\"(\", \"\").replace(\")\", \"\") for lst in split_release_dates]\n",
    "    out_df = pd.DataFrame()\n",
    "    out_df[\"title\"] = titles\n",
    "    out_df[\"release_date\"] = release_dates_to_df\n",
    "    out_df[\"box_office\"] = box_offices\n",
    "    return out_df\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Define a function named `create_trilogy_df` that is able to concatenate the 2 DataFrames obtained from previous exercises.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: a (6, 4) DataFrame.\n",
    "\n",
    "```\n",
    "                        title release_date  box_office           director\n",
    "0  The Fellowship of the Ring   2001-12-19   897690072      Peter Jackson\n",
    "1              The Two Towers   2002-12-18   947495095      Peter Jackson\n",
    "2      The Return of the King   2003-12-17  1146030912      Peter Jackson\n",
    "3               Batman Begins   2005-06-15   374218673  Christopher Nolan\n",
    "4             The Dark Knight   2008-07-18  1004934033  Christopher Nolan\n",
    "5       The Dark Knight Rises   2012-07-20  1084939099  Christopher Nolan\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trilogy_df():\n",
    "    \"\"\"\n",
    "    >>> trilogy_df = create_trilogy_df()\n",
    "    >>> print(type(trilogy_df))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    >>> print(trilogy_df.shape)\n",
    "    (6, 4)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    dark_knight_trilogy = extract_dark_knight_trilogy(\"https://simple.wikipedia.org/wiki/The_Dark_Knight_Trilogy\")\n",
    "    lord_of_the_rings_trilogy = extract_lord_of_the_rings_trilogy(\"https://en.wikipedia.org/wiki/The_Lord_of_the_Rings_(film_series)\")\n",
    "    out_df = pd.concat([lord_of_the_rings_trilogy, dark_knight_trilogy], ignore_index=True)\n",
    "    directors = [\"Peter Jackson\"] * 3 + [\"Christopher Nolan\"] * 3\n",
    "    col_loc = out_df.shape[1]\n",
    "    out_df.insert(col_loc, \"director\", directors)\n",
    "    return out_df\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 執行測試！\n",
    "\n",
    "Kernel -> Restart & Run All -> Restart and Run All Cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_01_extract_team_names (__main__.TestWebScraping) ... ok\n",
      "test_02_extract_store_addresses (__main__.TestWebScraping) ... ok\n",
      "test_03_extract_movie_titles (__main__.TestWebScraping) ... ok\n",
      "test_04_extract_movie_ratings (__main__.TestWebScraping) ... ok\n",
      "test_05_extract_movie_table (__main__.TestWebScraping) ... ok\n",
      "test_06_extract_dark_knight_release_dates (__main__.TestWebScraping) ... ok\n",
      "test_07_extract_dark_knight_box_offices (__main__.TestWebScraping) ... ok\n",
      "test_08_extract_dark_knight_trilogy (__main__.TestWebScraping) ... ok\n",
      "test_09_extract_lord_of_the_rings_trilogy (__main__.TestWebScraping) ... ok\n",
      "test_10_create_trilogy_df (__main__.TestWebScraping) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 4.469s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestWebScraping(unittest.TestCase):\n",
    "    def test_01_extract_team_names(self):\n",
    "        team_names = extract_team_names('teams.json')\n",
    "        self.assertEqual(len(team_names), 30)\n",
    "        self.assertTrue(\"Boston Celtics\" in team_names)\n",
    "        self.assertTrue(\"Brooklyn Nets\" in team_names)\n",
    "        self.assertTrue(\"Los Angeles Lakers\" in team_names)\n",
    "        self.assertTrue(\"Phoenix Suns\" in team_names)\n",
    "    def test_02_extract_store_addresses(self):\n",
    "        store_addresses = extract_store_addresses('stores.xml')\n",
    "        self.assertEqual(len(store_addresses), 74)\n",
    "        self.assertTrue('台北市信義區信義路五段7號35樓' in store_addresses)\n",
    "        self.assertTrue('台北市信義區吳興街156巷2弄2號4號1樓' in store_addresses)\n",
    "        self.assertTrue('台北市信義區忠孝東路五段68號24樓' in store_addresses)\n",
    "        self.assertTrue('台北市信義區虎林街85號' in store_addresses)\n",
    "    def test_03_extract_movie_titles(self):\n",
    "        movie_titles = extract_movie_titles('movies.html')\n",
    "        self.assertEqual(len(movie_titles), 250)\n",
    "        self.assertTrue('The Shawshank Redemption' in movie_titles)\n",
    "        self.assertTrue('The Godfather' in movie_titles)\n",
    "        self.assertTrue('The Dark Knight' in movie_titles)\n",
    "        self.assertTrue('Forrest Gump' in movie_titles)\n",
    "    def test_04_extract_movie_ratings(self):\n",
    "        movie_ratings = extract_movie_ratings('movies.html')\n",
    "        self.assertEqual(len(movie_ratings), 250)\n",
    "        self.assertAlmostEqual(max(movie_ratings), 9.2)\n",
    "        self.assertAlmostEqual(min(movie_ratings), 8.0)\n",
    "        self.assertAlmostEqual(sum(movie_ratings) / len(movie_ratings), 8.253999999999975)\n",
    "    def test_05_extract_movie_table(self):\n",
    "        movie_table = extract_movie_table('movies.html')\n",
    "        self.assertIsInstance(movie_table, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(movie_table.shape, (250, 4))\n",
    "        self.assertEqual(movie_table[\"release_year\"].min(), 1921)\n",
    "        self.assertEqual(movie_table[\"release_year\"].max(), 2020)\n",
    "    def test_06_extract_dark_knight_release_dates(self):\n",
    "        titles, release_dates = extract_dark_knight_release_dates(\"https://simple.wikipedia.org/wiki/The_Dark_Knight_Trilogy\")\n",
    "        self.assertEqual(titles, ['Batman Begins', 'The Dark Knight', 'The Dark Knight Rises'])\n",
    "        self.assertEqual(release_dates, ['June 15, 2005', 'July 18, 2008', 'July 20, 2012'])\n",
    "    def test_07_extract_dark_knight_box_offices(self):\n",
    "        titles, box_offices = extract_dark_knight_box_offices(\"https://simple.wikipedia.org/wiki/The_Dark_Knight_Trilogy\")\n",
    "        self.assertEqual(titles, ['Batman Begins', 'The Dark Knight', 'The Dark Knight Rises'])\n",
    "        self.assertEqual(box_offices, ['$374,218,673', '$1,004,934,033', '$1,084,939,099'])\n",
    "    def test_08_extract_dark_knight_trilogy(self):\n",
    "        dark_knight_trilogy = extract_dark_knight_trilogy(\"https://simple.wikipedia.org/wiki/The_Dark_Knight_Trilogy\")\n",
    "        self.assertIsInstance(dark_knight_trilogy, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(dark_knight_trilogy.shape, (3, 3))\n",
    "    def test_09_extract_lord_of_the_rings_trilogy(self):\n",
    "        lord_of_the_rings_trilogy = extract_lord_of_the_rings_trilogy(\"https://en.wikipedia.org/wiki/The_Lord_of_the_Rings_(film_series)\")\n",
    "        self.assertIsInstance(lord_of_the_rings_trilogy, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(lord_of_the_rings_trilogy.shape, (3, 3))\n",
    "    def test_10_create_trilogy_df(self):\n",
    "        trilogy_df = create_trilogy_df()\n",
    "        self.assertIsInstance(trilogy_df, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(trilogy_df.shape, (6, 4))\n",
    "        \n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestWebScraping)\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "test_results = runner.run(suite)\n",
    "number_of_failures = len(test_results.failures)\n",
    "number_of_errors = len(test_results.errors)\n",
    "number_of_test_runs = test_results.testsRun\n",
    "number_of_successes = number_of_test_runs - (number_of_failures + number_of_errors)\n",
    "cwd = os.getcwd()\n",
    "folder_name = cwd.split(\"/\")[-1]\n",
    "with open(\"../exercise_index.json\", \"r\") as content:\n",
    "    exercise_index = json.load(content)\n",
    "chapter_name = exercise_index[folder_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你在「以 Python 擷取網路資料」章節中的 10 道 Python 練習答對了 10 題。\n"
     ]
    }
   ],
   "source": [
    "print(\"你在「{}」章節中的 {} 道 Python 練習答對了 {} 題。\".format(chapter_name, number_of_test_runs, number_of_successes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Data Science",
   "language": "python",
   "name": "pyds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
