{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Python 資料分析\n",
    "\n",
    "> 以 Pandas 處理表格式資料\n",
    "\n",
    "[數據交點](https://www.datainpoint.com/) | 郭耀仁 <yaojenkuo@datainpoint.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 練習題指引\n",
    "\n",
    "- 第一個程式碼儲存格會將可能用得到的模組（套件）以及單元測試 `unittest` 載入。\n",
    "- 如果練習題需要載入檔案，檔案與練習題存放在同個資料夾中，意即我們可以指定工作目錄來載入。\n",
    "- 練習題已經定義好函數或者類別的名稱以及參數名稱，我們只需要寫作主體。\n",
    "- 函數或者類別的 `\"\"\"docstring\"\"\"` 部分會描述測試如何進行。\n",
    "- 觀察 `\"\"\"docstring\"\"\"` 的部分能夠暸解輸入以及預期輸出之間的關係，能幫助我們更暸解題目。\n",
    "- 請在 `### BEGIN SOLUTION` 與 `### END SOLUTION` 這兩個單行註解之間寫作函數或者類別的主體。\n",
    "- 執行測試的方式為點選上方選單的 Kernel -> Restart Kernel And Run All Cells -> Restart。\n",
    "- 可以每寫一題就執行測試，也可以全部寫完再執行測試。\n",
    "- 練習題閒置超過 10 分鐘會自動斷線，這時只要重新點選練習題連結即可重新啟動。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Define a function named `create_nba_teams` that is able to create a DataFrame as expected given a JSON file `teams.json`.\n",
    "\n",
    "- Expected inputs: a JSON file `teams.json`.\n",
    "- Expected outputs: a (30, 5) DataFrame.\n",
    "\n",
    "```\n",
    "   tricode confName    divName           city                fullName\n",
    "0      ATL     East  Southeast        Atlanta           Atlanta Hawks\n",
    "1      BOS     East   Atlantic         Boston          Boston Celtics\n",
    "2      BKN     East   Atlantic       Brooklyn           Brooklyn Nets\n",
    "3      CHA     East  Southeast      Charlotte       Charlotte Hornets\n",
    "4      CHI     East    Central        Chicago           Chicago Bulls\n",
    "5      CLE     East    Central      Cleveland     Cleveland Cavaliers\n",
    "6      DAL     West  Southwest         Dallas        Dallas Mavericks\n",
    "7      DEN     West  Northwest         Denver          Denver Nuggets\n",
    "8      DET     East    Central        Detroit         Detroit Pistons\n",
    "9      GSW     West    Pacific   Golden State   Golden State Warriors\n",
    "10     HOU     West  Southwest        Houston         Houston Rockets\n",
    "11     IND     East    Central        Indiana          Indiana Pacers\n",
    "12     LAC     West    Pacific             LA             LA Clippers\n",
    "13     LAL     West    Pacific    Los Angeles      Los Angeles Lakers\n",
    "14     MEM     West  Southwest        Memphis       Memphis Grizzlies\n",
    "15     MIA     East  Southeast          Miami              Miami Heat\n",
    "16     MIL     East    Central      Milwaukee         Milwaukee Bucks\n",
    "17     MIN     West  Northwest      Minnesota  Minnesota Timberwolves\n",
    "18     NOP     West  Southwest    New Orleans    New Orleans Pelicans\n",
    "19     NYK     East   Atlantic       New York         New York Knicks\n",
    "20     OKC     West  Northwest  Oklahoma City   Oklahoma City Thunder\n",
    "21     ORL     East  Southeast        Orlando           Orlando Magic\n",
    "22     PHI     East   Atlantic   Philadelphia      Philadelphia 76ers\n",
    "23     PHX     West    Pacific        Phoenix            Phoenix Suns\n",
    "24     POR     West  Northwest       Portland  Portland Trail Blazers\n",
    "25     SAC     West    Pacific     Sacramento        Sacramento Kings\n",
    "26     SAS     West  Southwest    San Antonio       San Antonio Spurs\n",
    "27     TOR     East   Atlantic        Toronto         Toronto Raptors\n",
    "28     UTA     West  Northwest           Utah               Utah Jazz\n",
    "29     WAS     East  Southeast     Washington      Washington Wizards\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nba_teams(json_file_path):\n",
    "    \"\"\"\n",
    "    >>> nba_teams = create_nba_teams('teams.json')\n",
    "    >>> print(type(nba_teams))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    >>> print(nba_teams.shape)\n",
    "    (30, 5)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    with open(json_file_path) as f:\n",
    "        teams_json = json.load(f)\n",
    "    teams_df = pd.DataFrame(teams_json['league']['standard'])\n",
    "    teams_df_selected = teams_df[['tricode', 'confName', 'divName', 'city', 'fullName']]\n",
    "    return teams_df_selected\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Define a function named `find_east_teams` that is able to create a DataFrame as expected given a JSON file `teams.json`.\n",
    "\n",
    "- Expected inputs: a JSON file `teams.json`.\n",
    "- Expected outputs: a (15, 5) DataFrame.\n",
    "\n",
    "```\n",
    "   tricode confName    divName          city             fullName\n",
    "0      ATL     East  Southeast       Atlanta        Atlanta Hawks\n",
    "1      BOS     East   Atlantic        Boston       Boston Celtics\n",
    "2      BKN     East   Atlantic      Brooklyn        Brooklyn Nets\n",
    "3      CHA     East  Southeast     Charlotte    Charlotte Hornets\n",
    "4      CHI     East    Central       Chicago        Chicago Bulls\n",
    "5      CLE     East    Central     Cleveland  Cleveland Cavaliers\n",
    "6      DET     East    Central       Detroit      Detroit Pistons\n",
    "7      IND     East    Central       Indiana       Indiana Pacers\n",
    "8      MIA     East  Southeast         Miami           Miami Heat\n",
    "9      MIL     East    Central     Milwaukee      Milwaukee Bucks\n",
    "10     NYK     East   Atlantic      New York      New York Knicks\n",
    "11     ORL     East  Southeast       Orlando        Orlando Magic\n",
    "12     PHI     East   Atlantic  Philadelphia   Philadelphia 76ers\n",
    "13     TOR     East   Atlantic       Toronto      Toronto Raptors\n",
    "14     WAS     East  Southeast    Washington   Washington Wizards\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_east_teams(json_file_path):\n",
    "    \"\"\"\n",
    "    >>> east_teams = find_east_teams('teams.json')\n",
    "    >>> print(type(east_teams))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    >>> print(east_teams.shape)\n",
    "    (15, 5)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    teams_df = create_nba_teams(json_file_path)\n",
    "    east_teams = teams_df[teams_df['confName'] == 'East']\n",
    "    return east_teams.reset_index(drop=True)\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Define a function named `create_head_coaches` that is able to create a DataFrame as expected given a JSON file `coaches.json`.\n",
    "\n",
    "- Expected inputs: a JSON file `coaches.json`.\n",
    "- Expected outputs: a (30, 3) DataFrame.\n",
    "\n",
    "```\n",
    "   team_tricode  first_name    last_name\n",
    "0           PHI         Doc       Rivers\n",
    "1           POR    Chauncey      Billups\n",
    "2           MIL        Mike  Budenholzer\n",
    "3           CHI       Billy      Donovan\n",
    "4           CLE  John-Blair  Bickerstaff\n",
    "5           BOS         Ime        Udoka\n",
    "6           LAC      Tyronn          Lue\n",
    "7           MEM      Taylor      Jenkins\n",
    "8           ATL        Nate     McMillan\n",
    "9           MIA        Erik    Spoelstra\n",
    "10          CHA       James      Borrego\n",
    "11          UTA        Quin       Snyder\n",
    "12          SAC        Luke       Walton\n",
    "13          NYK         Tom    Thibodeau\n",
    "14          LAL       Frank        Vogel\n",
    "15          ORL      Jamahl       Mosley\n",
    "16          DAL       Jason         Kidd\n",
    "17          BKN       Steve         Nash\n",
    "18          DEN     Michael       Malone\n",
    "19          IND        Rick     Carlisle\n",
    "20          NOP      Willie        Green\n",
    "21          DET       Dwane        Casey\n",
    "22          TOR        Nick        Nurse\n",
    "23          HOU     Stephen        Silas\n",
    "24          SAS       Gregg     Popovich\n",
    "25          PHX       Monty     Williams\n",
    "26          OKC        Mark   Daigneault\n",
    "27          MIN       Chris        Finch\n",
    "28          GSW       Steve         Kerr\n",
    "29          WAS         Wes       Unseld\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_head_coaches(json_file_path):\n",
    "    \"\"\"\n",
    "    >>> head_coaches = create_head_coaches('coaches.json')\n",
    "    >>> print(type(head_coaches))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    >>> print(head_coaches.shape)\n",
    "    (30, 3)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    with open(json_file_path) as f:\n",
    "        coaches_json = json.load(f)\n",
    "    coach_list = coaches_json['league']['standard']\n",
    "    first_names, last_names, team_tricodes = [], [], []\n",
    "    for coach in coach_list:\n",
    "        if not coach['isAssistant']:\n",
    "            first_names.append(coach['firstName'])\n",
    "            last_names.append(coach['lastName'])\n",
    "            team_tricodes.append(coach['teamSitesOnly']['teamTricode'])\n",
    "    out = pd.DataFrame()\n",
    "    out['team_tricode'] = team_tricodes\n",
    "    out['first_name'] = first_names\n",
    "    out['last_name'] = last_names\n",
    "    return out\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Define a function named `create_nba_player_heights` that is able to create a DataFrame as expected given a JSON file `players.json`.\n",
    "\n",
    "PS You have to exclude the players who is not active(`isActive == False`).\n",
    "\n",
    "- Expected inputs: a JSON file `players.json`.\n",
    "- Expected outputs: a (503, 3) DataFrame.\n",
    "\n",
    "```\n",
    "    first_name         last_name  height_meter\n",
    "0     Precious           Achiuwa          2.03\n",
    "1       Steven             Adams          2.11\n",
    "2          Bam           Adebayo          2.06\n",
    "3      Ty-Shon         Alexander          1.90\n",
    "4      Nickeil  Alexander-Walker          1.98\n",
    "..         ...               ...           ...\n",
    "498   Thaddeus             Young          2.03\n",
    "499       Trae             Young          1.85\n",
    "500       Omer         Yurtseven          2.13\n",
    "501       Cody            Zeller          2.11\n",
    "502      Ivica             Zubac          2.13\n",
    "\n",
    "[503 rows x 3 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nba_player_heights(json_file_path):\n",
    "    \"\"\"\n",
    "    >>> nba_player_heights = create_nba_player_heights('players.json')\n",
    "    >>> print(type(nba_player_heights))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    >>> print(nba_player_heights.shape)\n",
    "    (503, 3)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    with open(json_file_path) as f:\n",
    "        players_json = json.load(f)\n",
    "    player_list = players_json['league']['standard']\n",
    "    first_names, last_names, height_meters = [], [], []\n",
    "    for player in player_list:\n",
    "        if player['isActive']:\n",
    "            first_names.append(player['firstName'])\n",
    "            last_names.append(player['lastName'])\n",
    "            height_meters.append(player['heightMeters'])\n",
    "    out = pd.DataFrame()\n",
    "    out['first_name'] = first_names\n",
    "    out['last_name'] = last_names\n",
    "    out['height_meter'] = np.array(height_meters, dtype=float)\n",
    "    return out\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Define a function named `find_tallest_shortest_players` that is able to create a DataFrame as expected given a JSON file `players.json`.\n",
    "\n",
    "PS You have to exclude the players who is not active(`isActive == False`).\n",
    "\n",
    "- Expected inputs: a JSON file `players.json`.\n",
    "- Expected outputs: a (5, 4) DataFrame.\n",
    "\n",
    "```\n",
    "  first_name last_name  height_meter       tag\n",
    "0    Facundo  Campazzo          1.78  shortest\n",
    "1      Tacko      Fall          2.26   tallest\n",
    "2      Jared    Harper          1.78  shortest\n",
    "3     Markus    Howard          1.78  shortest\n",
    "4    Tremont    Waters          1.78  shortest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tallest_shortest_players(json_file_path):\n",
    "    \"\"\"\n",
    "    >>> tallest_shortest_players = find_tallest_shortest_players('players.json')\n",
    "    >>> print(type(tallest_shortest_players))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    >>> print(tallest_shortest_players.shape)\n",
    "    (5, 4)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    nba_player_heights = create_nba_player_heights(json_file_path)\n",
    "    max_height = nba_player_heights['height_meter'].max()\n",
    "    min_height = nba_player_heights['height_meter'].min()\n",
    "    condition = (nba_player_heights['height_meter'] == max_height) | (nba_player_heights['height_meter'] == min_height)\n",
    "    out = nba_player_heights[condition]\n",
    "    tag = out['height_meter'].map(lambda x: 'tallest' if x == max_height else 'shortest').values\n",
    "    ncols = out.shape[1]\n",
    "    out.insert(ncols, 'tag', tag)\n",
    "    return out.reset_index(drop=True)\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. Define a function named `calculate_death_rate_by_countries` according to the following formula given `07-22-2021.csv`.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Death Rate} = \\frac{\\text{Deaths}}{\\text{Confirmed}}\n",
    "\\end{equation}\n",
    "\n",
    "- Expected inputs: a CSV file `07-22-2021.csv`.\n",
    "- Expected outputs: a Series of length 195.\n",
    "\n",
    "```\n",
    "Country_Region\n",
    "Vanuatu                 0.250000\n",
    "MS Zaandam              0.222222\n",
    "Yemen                   0.195972\n",
    "Peru                    0.093219\n",
    "Mexico                  0.087693\n",
    "                          ...   \n",
    "Summer Olympics 2020    0.000000\n",
    "Samoa                   0.000000\n",
    "Solomon Islands         0.000000\n",
    "Marshall Islands        0.000000\n",
    "Palau                        NaN\n",
    "Length: 195, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_death_rate_by_countries(csv_file_path):\n",
    "    \"\"\"\n",
    "    >>> death_rate_by_countries = calculate_death_rate_by_countries('07-22-2021.csv')\n",
    "    >>> print(type(death_rate_by_countries))\n",
    "    <class 'pandas.core.series.Series'>\n",
    "    >>> print(death_rate_by_countries.size)\n",
    "    195\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    daily_report = pd.read_csv(csv_file_path)\n",
    "    groupby_summary = daily_report.groupby('Country_Region')[['Confirmed', 'Deaths']].sum()\n",
    "    out = groupby_summary['Deaths'] / groupby_summary['Confirmed']\n",
    "    return out.sort_values(ascending=False)\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. Define a function named `calculate_confirmed_rate_by_countries` according to the following formula given `07-22-2021.csv` and `UID_ISO_FIPS_LookUp_Table.csv`.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Confirmed Rate} = \\frac{\\text{Confirmed}}{\\text{Population}}\n",
    "\\end{equation}\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: a (195, 3) DataFrame.\n",
    "\n",
    "```\n",
    "                      Confirmed  Population  Confirmed_Rate\n",
    "Country_Region                                             \n",
    "Summer Olympics 2020         91         0.0             inf\n",
    "Diamond Princess            712         0.0             inf\n",
    "MS Zaandam                    9         0.0             inf\n",
    "Andorra                   14464     77265.0        0.187200\n",
    "Seychelles                17747     98340.0        0.180466\n",
    "...                         ...         ...             ...\n",
    "Samoa                         3    196130.0        0.000015\n",
    "Vanuatu                       4    292680.0        0.000014\n",
    "Micronesia                    1    113815.0        0.000009\n",
    "Tanzania                    509  59734213.0        0.000009\n",
    "Palau                         0     18008.0        0.000000\n",
    "\n",
    "[195 rows x 3 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confirmed_rate_by_countries():\n",
    "    \"\"\"\n",
    "    >>> confirmed_rate_by_countries = calculate_confirmed_rate_by_countries()\n",
    "    >>> print(type(confirmed_rate_by_countries))\n",
    "    pandas.core.frame.DataFrame\n",
    "    >>> print(confirmed_rate_by_countries.shape)\n",
    "    (195, 3)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    daily_report = pd.read_csv(\"07-22-2021.csv\")\n",
    "    lookup_table = pd.read_csv(\"UID_ISO_FIPS_LookUp_Table.csv\")\n",
    "    confirmed_by_countries = pd.DataFrame(daily_report.groupby('Country_Region')['Confirmed'].sum())\n",
    "    population_by_countries = pd.DataFrame(lookup_table.groupby('Country_Region')['Population'].sum())\n",
    "    out = confirmed_by_countries.join(population_by_countries)\n",
    "    out['Confirmed_Rate'] = out['Confirmed'] / out['Population']\n",
    "    return out.sort_values('Confirmed_Rate', ascending=False)\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. Define a function named `find_death_confirmed_rate_of_taiwan` that is able to retrieve the death rate/confirmed rate of Taiwan given `07-22-2021.csv` and `UID_ISO_FIPS_LookUp_Table.csv`.\n",
    "\n",
    "PS Taiwan might not be \"Taiwan\" in COVID-19 Data Repository by CSSE at Johns Hopkins University.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: a (1, 5) DataFrame.\n",
    "\n",
    "```\n",
    "  Country_Region  Confirmed  Population  Confirmed_Rate  Death_Rate\n",
    "0        Taiwan*      15511  23816775.0        0.000651    0.050416\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_death_confirmed_rate_of_taiwan():\n",
    "    \"\"\"\n",
    "    >>> death_confirmed_rate_of_taiwan = find_death_confirmed_rate_of_taiwan()\n",
    "    >>> print(type(death_confirmed_rate_of_taiwan))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    >>> print(death_confirmed_rate_of_taiwan.shape)\n",
    "    (1, 5)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    death_rate_by_countries = calculate_death_rate_by_countries('07-22-2021.csv')\n",
    "    death_rate_by_countries = pd.DataFrame(death_rate_by_countries)\n",
    "    death_rate_by_countries.columns = [\"Death_Rate\"]\n",
    "    confirmed_rate_by_countries = calculate_confirmed_rate_by_countries()\n",
    "    joined_df = confirmed_rate_by_countries.join(death_rate_by_countries)\n",
    "    tw_df = joined_df[joined_df.index == 'Taiwan*']\n",
    "    return tw_df.reset_index()\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Define a function named `summarize_time_series` that is able to summarize the summation of confirmed and deaths cases by `Country/Region` given `time_series_covid19_confirmed_global.csv` and `time_series_covid19_deaths_global.csv`.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: a (106860, 4) DataFrame.\n",
    "\n",
    "```\n",
    "       Country/Region       Date  Confirmed  Deaths\n",
    "0         Afghanistan 2020-01-22          0       0\n",
    "1         Afghanistan 2020-01-23          0       0\n",
    "2         Afghanistan 2020-01-24          0       0\n",
    "3         Afghanistan 2020-01-25          0       0\n",
    "4         Afghanistan 2020-01-26          0       0\n",
    "...               ...        ...        ...     ...\n",
    "106855       Zimbabwe 2021-07-18      83619    2622\n",
    "106856       Zimbabwe 2021-07-19      85732    2697\n",
    "106857       Zimbabwe 2021-07-20      88415    2747\n",
    "106858       Zimbabwe 2021-07-21      91120    2809\n",
    "106859       Zimbabwe 2021-07-22      93421    2870\n",
    "\n",
    "[106860 rows x 4 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_time_series():\n",
    "    \"\"\"\n",
    "    >>> summarized_time_series = summarize_time_series()\n",
    "    >>> print(type(summarized_time_series))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    >>> print(summarized_time_series.shape)\n",
    "    (106860, 4)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    time_series_confirmed = pd.read_csv('time_series_covid19_confirmed_global.csv')\n",
    "    time_series_deaths = pd.read_csv('time_series_covid19_deaths_global.csv')\n",
    "    time_series_confirmed_selected = time_series_confirmed.drop(['Lat', 'Long'], axis=1)\n",
    "    time_series_deaths_selected = time_series_deaths.drop(['Lat', 'Long'], axis=1)\n",
    "    idVars = ['Province/State', 'Country/Region']\n",
    "    transposed_confirmed = pd.melt(time_series_confirmed_selected, id_vars=idVars, var_name='Date', value_name='Confirmed')\n",
    "    transposed_deaths = pd.melt(time_series_deaths_selected, id_vars=idVars, var_name='Date', value_name='Deaths')\n",
    "    transposed_confirmed_groupby = pd.DataFrame(transposed_confirmed.groupby(['Country/Region', 'Date'])['Confirmed'].sum())\n",
    "    transposed_deaths_groupby = pd.DataFrame(transposed_deaths.groupby(['Country/Region', 'Date'])['Deaths'].sum())\n",
    "    out = transposed_confirmed_groupby.join(transposed_deaths_groupby).reset_index()\n",
    "    out['Date'] = pd.to_datetime(out['Date'])\n",
    "    return out.sort_values(['Country/Region', 'Date']).reset_index(drop=True)\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Define a function named `calculate_daily_cases_of_taiwan` that is able to calculate the daily cases of Taiwan a DataFrame as expected given `time_series_covid19_confirmed_global.csv` and `time_series_covid19_deaths_global.csv`.\n",
    "\n",
    "- Expected inputs: None.\n",
    "- Expected outputs: a (548, 5) DataFrame.\n",
    "\n",
    "```\n",
    "           Country/Region  Confirmed  Deaths  Daily_Confirmed  Daily_Deaths\n",
    "Date                                                                       \n",
    "2020-01-22         Taiwan          1       0              NaN           NaN\n",
    "2020-01-23         Taiwan          1       0              0.0           0.0\n",
    "2020-01-24         Taiwan          3       0              2.0           0.0\n",
    "2020-01-25         Taiwan          3       0              0.0           0.0\n",
    "2020-01-26         Taiwan          4       0              1.0           0.0\n",
    "...                   ...        ...     ...              ...           ...\n",
    "2021-07-18         Taiwan      15408     768             18.0           4.0\n",
    "2021-07-19         Taiwan      15429     769             21.0           1.0\n",
    "2021-07-20         Taiwan      15453     773             24.0           4.0\n",
    "2021-07-21         Taiwan      15478     778             25.0           5.0\n",
    "2021-07-22         Taiwan      15511     782             33.0           4.0\n",
    "\n",
    "[548 rows x 5 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_daily_cases_of_taiwan():\n",
    "    \"\"\"\n",
    "    >>> daily_cases_of_taiwan = calculate_daily_cases_of_taiwan()\n",
    "    >>> print(type(daily_cases_of_taiwan))\n",
    "    <class 'pandas.core.frame.DataFrame'>\n",
    "    >>> print(daily_cases_of_taiwan.shape)\n",
    "    (548, 5)\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    ts = summarize_time_series()\n",
    "    ts_tw = ts[ts['Country/Region'] == 'Taiwan*']\n",
    "    daily_confirmed = np.diff(ts_tw['Confirmed'].values.astype(float))\n",
    "    daily_deaths = np.diff(ts_tw['Deaths'].values.astype(float))\n",
    "    daily_confirmed = np.insert(daily_confirmed, 0, np.nan)\n",
    "    daily_deaths = np.insert(daily_deaths, 0, np.nan)\n",
    "    ts_tw.insert(ts_tw.shape[1], 'Daily_Confirmed', daily_confirmed)\n",
    "    ts_tw.insert(ts_tw.shape[1], 'Daily_Deaths', daily_deaths)\n",
    "    ts_tw_set_index = ts_tw.set_index('Date')\n",
    "    out = ts_tw_set_index.replace(to_replace={\"\\*\": \"\"}, regex=True)\n",
    "    return out\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## 執行測試！\n",
    "\n",
    "Kernel -> Restart Kernel And Run All Cells -> Restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_01_create_nba_teams (__main__.TestDataFrameWranglingWithPandasAdvanced) ... ok\n",
      "test_02_find_east_teams (__main__.TestDataFrameWranglingWithPandasAdvanced) ... ok\n",
      "test_03_create_head_coaches (__main__.TestDataFrameWranglingWithPandasAdvanced) ... ok\n",
      "test_04_create_nba_player_heights (__main__.TestDataFrameWranglingWithPandasAdvanced) ... ok\n",
      "test_05_find_tallest_shortest_players (__main__.TestDataFrameWranglingWithPandasAdvanced) ... ok\n",
      "test_06_calculate_death_rate_by_countries (__main__.TestDataFrameWranglingWithPandasAdvanced) ... ok\n",
      "test_07_calculate_confirmed_rate_by_countries (__main__.TestDataFrameWranglingWithPandasAdvanced) ... ok\n",
      "test_08_find_death_confirmed_rate_of_taiwan (__main__.TestDataFrameWranglingWithPandasAdvanced) ... ok\n",
      "test_09_summarize_time_series (__main__.TestDataFrameWranglingWithPandasAdvanced) ... ok\n",
      "test_10_calculate_daily_cases_of_taiwan (__main__.TestDataFrameWranglingWithPandasAdvanced) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 16.280s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestDataFrameWranglingWithPandasAdvanced(unittest.TestCase):\n",
    "    def test_01_create_nba_teams(self):\n",
    "        nba_teams = create_nba_teams('teams.json')\n",
    "        self.assertIsInstance(nba_teams, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(nba_teams.shape, (30, 5))\n",
    "        column_names = nba_teams.columns\n",
    "        self.assertTrue('tricode' in column_names)\n",
    "        self.assertTrue('confName' in column_names)\n",
    "        self.assertTrue('divName' in column_names)\n",
    "        self.assertTrue('city' in column_names)\n",
    "        self.assertTrue('fullName' in column_names)\n",
    "    def test_02_find_east_teams(self):\n",
    "        east_teams = find_east_teams('teams.json')\n",
    "        self.assertIsInstance(east_teams, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(east_teams.shape, (15, 5))\n",
    "        div_names = east_teams['divName'].values\n",
    "        self.assertTrue('Atlantic' in div_names)\n",
    "        self.assertTrue('Southeast' in div_names)\n",
    "        self.assertTrue('Central' in div_names)\n",
    "    def test_03_create_head_coaches(self):\n",
    "        head_coaches = create_head_coaches('coaches.json')\n",
    "        self.assertIsInstance(head_coaches, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(head_coaches.shape, (30, 3))\n",
    "        tricodes = head_coaches.iloc[:, 0].values\n",
    "        self.assertTrue('PHI' in tricodes)\n",
    "        self.assertTrue('BKN' in tricodes)\n",
    "        self.assertTrue('WAS' in tricodes)\n",
    "    def test_04_create_nba_player_heights(self):\n",
    "        nba_player_heights = create_nba_player_heights('players.json')\n",
    "        self.assertIsInstance(nba_player_heights, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(nba_player_heights.shape, (503, 3))\n",
    "    def test_05_find_tallest_shortest_players(self):\n",
    "        tallest_shortest_players = find_tallest_shortest_players('players.json')\n",
    "        self.assertIsInstance(tallest_shortest_players, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(tallest_shortest_players.shape, (5, 4))\n",
    "        tags = tallest_shortest_players.iloc[:, 3].values\n",
    "        self.assertTrue('tallest' in tags)\n",
    "        self.assertTrue('shortest' in tags)\n",
    "        first_names = tallest_shortest_players.iloc[:, 0].values\n",
    "        self.assertTrue('Tacko' in first_names)\n",
    "        last_names = tallest_shortest_players.iloc[:, 1].values\n",
    "        self.assertTrue('Fall' in last_names)\n",
    "    def test_06_calculate_death_rate_by_countries(self):\n",
    "        death_rate_by_countries = calculate_death_rate_by_countries('07-22-2021.csv')\n",
    "        self.assertIsInstance(death_rate_by_countries, pd.core.series.Series)\n",
    "        self.assertEqual(death_rate_by_countries.size, 195)\n",
    "        ser_index = death_rate_by_countries.index\n",
    "        self.assertTrue('Vanuatu' in ser_index)\n",
    "        self.assertTrue('MS Zaandam' in ser_index)\n",
    "        self.assertTrue('Yemen' in ser_index)\n",
    "        self.assertTrue('Mexico' in ser_index)\n",
    "        self.assertTrue('Sudan' in ser_index)\n",
    "    def test_07_calculate_confirmed_rate_by_countries(self):\n",
    "        confirmed_rate_by_countries = calculate_confirmed_rate_by_countries()\n",
    "        self.assertIsInstance(confirmed_rate_by_countries, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(confirmed_rate_by_countries.shape, (195, 3))\n",
    "        df_index = confirmed_rate_by_countries.index\n",
    "        self.assertTrue('Andorra' in df_index)\n",
    "        self.assertTrue('Montenegro' in df_index)\n",
    "        self.assertTrue('Czechia' in df_index)\n",
    "        df_columns = confirmed_rate_by_countries.columns\n",
    "        self.assertTrue('Confirmed' in df_columns)\n",
    "        self.assertTrue('Population' in df_columns)\n",
    "        self.assertTrue('Confirmed_Rate' in df_columns)\n",
    "    def test_08_find_death_confirmed_rate_of_taiwan(self):\n",
    "        death_confirmed_rate_of_taiwan = find_death_confirmed_rate_of_taiwan()\n",
    "        self.assertIsInstance(death_confirmed_rate_of_taiwan, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(death_confirmed_rate_of_taiwan.shape, (1, 5))\n",
    "    def test_09_summarize_time_series(self):\n",
    "        summarized_time_series = summarize_time_series()\n",
    "        self.assertIsInstance(summarized_time_series, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(summarized_time_series.shape, (106860, 4))\n",
    "    def test_10_calculate_daily_cases_of_taiwan(self):\n",
    "        daily_cases_of_taiwan = calculate_daily_cases_of_taiwan()\n",
    "        self.assertIsInstance(daily_cases_of_taiwan, pd.core.frame.DataFrame)\n",
    "        self.assertEqual(daily_cases_of_taiwan.shape, (548, 5))\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestDataFrameWranglingWithPandasAdvanced)\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "test_results = runner.run(suite)\n",
    "number_of_failures = len(test_results.failures)\n",
    "number_of_errors = len(test_results.errors)\n",
    "number_of_test_runs = test_results.testsRun\n",
    "number_of_successes = number_of_test_runs - (number_of_failures + number_of_errors)\n",
    "cwd = os.getcwd()\n",
    "folder_name = cwd.split(\"/\")[-1]\n",
    "with open(\"../exercise_index.json\", \"r\") as content:\n",
    "    exercise_index = json.load(content)\n",
    "chapter_name = exercise_index[folder_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你在「以 Pandas 處理表格式資料」章節中的 10 道 Python 練習答對了 10 題。\n"
     ]
    }
   ],
   "source": [
    "print(\"你在「{}」章節中的 {} 道 Python 練習答對了 {} 題。\".format(chapter_name, number_of_test_runs, number_of_successes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Data Science",
   "language": "python",
   "name": "pyds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
